Modular Design:
MediaPipe‚Äôs new Tasks API is built to be modular and consistent across different types of tasks (vision, audio, etc.). 
This means that instead of having one monolithic API, they separate out configuration, model loading, and processing into different components.
The vision module is just a namespace for all vision-related tasks (like face detection). 
When you see from mediapipe.tasks.python import vision, it means ‚Äúimport the vision tasks (e.g., face detection, object detection) so we can use them.‚Äù


Configuration Objects (BaseOptions & FaceDetectorOptions):
BaseOptions: This object holds basic configuration details that many tasks need, like where to find the model file. 
Think of it as setting the foundation‚Äîtelling the system, ‚ÄúHey, load this model from here.‚Äù
it also takes in a (model_asset_path=) paramter which is a string giving the path


FaceDetectorOptions: This is a more specific configuration for the face detector. 
It builds on BaseOptions and can include additional settings (like running mode). 
By creating a separate options object, MediaPipe lets you tweak the detector‚Äôs behavior without changing the code that actually runs detection.


In simple terms, when you write running_mode=vision.RunningMode.IMAGE, 
you‚Äôre telling the system to use the ‚ÄúIMAGE‚Äù mode instead of the default. 
If you don‚Äôt provide a value, the FaceDetectorOptions uses its 
built-in defaults‚Äîby default it processes images (running_mode is IMAGE) and 
uses standard settings that work for most cases, so you only need to override these 
if you have a special requirement (like video or live stream processing).


If you don‚Äôt provide any parameters, the default running mode is set to IMAGE. 
However, you must supply a BaseOptions object (with a valid model path or buffer) because without it, the model won‚Äôt be loaded.


Factory Method (create_from_options):
Instead of directly constructing a FaceDetector with a long list of parameters, MediaPipe uses a factory method‚Äîcreate_from_options(options). 
This method takes your configuration (the options objects) and creates an instance of the FaceDetector that‚Äôs fully set up.
This approach makes it easier to manage, extend, or modify the configuration without changing the detector‚Äôs internal code. 
It also hides some of the complexity behind the scenes, so you don‚Äôt need to worry about low-level details.


Behind the Scenes:
Underneath this Python API, MediaPipe is likely interacting with highly optimized C++ code that actually performs the face detection. 
The options you set in Python are passed down to this lower-level code.
The modular design means that if you later decide to use a different model 
or change a parameter (like the running mode from IMAGE to VIDEO), you just adjust the options and the rest of your code remains the same.

Collection of detected faces, where each face is represented as a detection proto message that contains a bounding box and 6 key points 
(right eye, left eye, nose tip, mouth center, right ear tragion, and left ear tragion). 
The bounding box is composed of xmin and width (both normalized to [0.0, 1.0] by the image width) and ymin and height 
(both normalized to [0.0, 1.0] by the image height). Each key point is composed of x and y, which are normalized to [0.0, 1.0] 
by the image width and height respectively.

line 66 on the main page chat said to possibly use this
image_width, image_height = capturedFrame.shape[1], capturedFrame.shape[0]
x = int(bbox.origin_x * image_width)
y = int(bbox.origin_y * image_height)
w = int(bbox.width * image_width)
h = int(bbox.height * image_height)




The cv2.rectangle() function needs:
	1.	The top-left corner of the rectangle (x, y).
	2.	The bottom-right corner of the rectangle (x + w, y + h).

üí° Why?
	‚Ä¢	The AI model gives you the starting point (x, y), which is the top-left corner.
	‚Ä¢	It also gives the width (w) and height (h) of the detected face.
	‚Ä¢	To find the bottom-right corner, you add:
	‚Ä¢	x + w ‚Üí Moves right by w pixels.
	‚Ä¢	y + h ‚Üí Moves down by h pixels.